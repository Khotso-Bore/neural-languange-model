{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9f71020b",
      "metadata": {
        "id": "9f71020b"
      },
      "source": [
        "#download data set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "eluylj51qOAz"
      },
      "id": "eluylj51qOAz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4457e628",
      "metadata": {
        "id": "4457e628"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14fccc7c",
      "metadata": {
        "id": "14fccc7c"
      },
      "outputs": [],
      "source": [
        "setswana_url = 'https://raw.githubusercontent.com/NLPforLRLsProjects/SAfriSenti-Corpus/refs/heads/main/setswana_tweets.csv'\n",
        "sesotho_url = 'https://raw.githubusercontent.com/NLPforLRLsProjects/SAfriSenti-Corpus/refs/heads/main/sesotho_tweets.csv'\n",
        "\n",
        "setswana_df = pd.read_csv(setswana_url)\n",
        "sesotho_df = pd.read_csv(sesotho_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e4912a7",
      "metadata": {
        "id": "3e4912a7"
      },
      "source": [
        "#tokenize dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "setswana_df['Final_Label'].unique()"
      ],
      "metadata": {
        "id": "-9rvpFJ_qJe7"
      },
      "id": "-9rvpFJ_qJe7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sesotho_df.rename(columns={'Final_labels': 'Final_Label'}, inplace=True)"
      ],
      "metadata": {
        "id": "cD5u7XddFkgk"
      },
      "id": "cD5u7XddFkgk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_to_int(x):\n",
        "  if x == 'positive':\n",
        "    return 1\n",
        "  elif x == 'negative':\n",
        "    return 0\n",
        "  else:\n",
        "    return 2\n"
      ],
      "metadata": {
        "id": "sE5L8MRcqkZq"
      },
      "id": "sE5L8MRcqkZq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sesotho_df.head()"
      ],
      "metadata": {
        "id": "3B0HZosqFSQY"
      },
      "id": "3B0HZosqFSQY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "setswana_df['Final_Label'] = [label_to_int(x) for x in setswana_df['Final_Label']]\n",
        "sesotho_df['Final_Label'] = [label_to_int(x) for x in sesotho_df['Final_Label']]"
      ],
      "metadata": {
        "id": "l1IlVAl4pcA7"
      },
      "id": "l1IlVAl4pcA7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import XLMRobertaTokenizer"
      ],
      "metadata": {
        "id": "6ABJuXMfqa-B"
      },
      "id": "6ABJuXMfqa-B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')"
      ],
      "metadata": {
        "id": "W4ZCTJF7nTyk"
      },
      "id": "W4ZCTJF7nTyk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "setswana_df['tokens'] = setswana_df['sentence'].apply(lambda x: tokenizer.tokenize(x))\n",
        "sesotho_df['tokens'] = sesotho_df['sentence'].apply(lambda x: tokenizer.tokenize(x))"
      ],
      "metadata": {
        "id": "Fo0f4l1WnhFj"
      },
      "id": "Fo0f4l1WnhFj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "setswana_df.head()"
      ],
      "metadata": {
        "id": "ZpPcYLiNp9m4"
      },
      "id": "ZpPcYLiNp9m4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sesotho_df.head()"
      ],
      "metadata": {
        "id": "6f9qoa0up-tE"
      },
      "id": "6f9qoa0up-tE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#process tokens"
      ],
      "metadata": {
        "id": "BiXJGjKNZ8I7"
      },
      "id": "BiXJGjKNZ8I7"
    },
    {
      "cell_type": "code",
      "source": [
        "setswana_encoding = tokenizer(setswana_df['sentence'].tolist(), padding=True, truncation=True, return_tensors='pt',max_length=64)\n",
        "sesotho_encoding = tokenizer(sesotho_df['sentence'].tolist(), padding=True, truncation=True, return_tensors='pt')"
      ],
      "metadata": {
        "id": "ajjkMCqTet7p"
      },
      "id": "ajjkMCqTet7p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "setswana_encoding"
      ],
      "metadata": {
        "id": "Mkdwe1RJeuzJ"
      },
      "id": "Mkdwe1RJeuzJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "import torch\n",
        "\n",
        "input_ids = setswana_encoding['input_ids']\n",
        "attention_mask = setswana_encoding['attention_mask']\n",
        "labels = torch.tensor(setswana_df['Final_Label'].tolist())\n",
        "\n"
      ],
      "metadata": {
        "id": "2L5AleO6crvL"
      },
      "id": "2L5AleO6crvL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "setswana_dataset = TensorDataset(input_ids, labels)\n",
        "train_size = int(0.8 * len(setswana_dataset))\n",
        "val_size = len(setswana_dataset) - train_size\n",
        "\n",
        "train_ds, val_ds = random_split(setswana_dataset, [train_size, val_size])\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=32)"
      ],
      "metadata": {
        "id": "8SHMKOfncoFn"
      },
      "id": "8SHMKOfncoFn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create neural model"
      ],
      "metadata": {
        "id": "kIFtdtevUZ4w"
      },
      "id": "kIFtdtevUZ4w"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TweetClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
        "        super(TweetClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.fc1 = nn.Linear(embed_dim * 64, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)              # (batch_size, seq_len, embed_dim)\n",
        "        flat = embedded.view(x.size(0), -1)       # Flatten: (batch_size, seq_len * embed_dim)\n",
        "        out = F.relu(self.fc1(flat))              # (batch_size, hidden_dim)\n",
        "        return self.fc2(out)                      # (batch_size, output_dim)\n"
      ],
      "metadata": {
        "id": "XLf0E89SZ5CS"
      },
      "id": "XLf0E89SZ5CS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TweetClassifier(vocab_size=tokenizer.vocab_size, embed_dim=64, hidden_dim=128, output_dim=3)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "TdbCa5MoGRmI"
      },
      "id": "TdbCa5MoGRmI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for xb, yb, in train_dl:\n",
        "        preds = model(xb)\n",
        "        loss = loss_fn(preds, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "YNYablv5EK3-"
      },
      "id": "YNYablv5EK3-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7K0P_NaLE-Q5"
      },
      "id": "7K0P_NaLE-Q5"
    },
    {
      "cell_type": "markdown",
      "id": "b0da7354",
      "metadata": {
        "id": "b0da7354"
      },
      "source": [
        "#evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in val_dl:\n",
        "        preds = model(xb)\n",
        "        predicted = torch.argmax(preds, dim=1)\n",
        "        correct += (predicted == yb).sum().item()\n",
        "        total += yb.size(0)\n",
        "\n",
        "print(f\"Validation Accuracy: {correct / total:.2%}\")\n"
      ],
      "metadata": {
        "id": "qWjbZ2WME9M3"
      },
      "id": "qWjbZ2WME9M3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}